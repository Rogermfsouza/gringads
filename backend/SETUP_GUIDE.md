# ðŸš€ GUIA DE SETUP - BACKEND GRINGADS

## âœ… O QUE FOI IMPLEMENTADO

### 1. ConfiguraÃ§Ãµes Base
- âœ… `SupabaseConfigService` - ConexÃ£o com banco de dados
- âœ… `FacebookConfigService` - ConfiguraÃ§Ãµes da API do Facebook
- âœ… Sistema de validaÃ§Ã£o de variÃ¡veis de ambiente
- âœ… Testes de conexÃ£o automÃ¡ticos

### 2. MÃ³dulo de AnÃºncios (Ads)
- âœ… **Entities** - Tipos e interfaces para anÃºncios
- âœ… **DTOs** - CreateAdDto, FilterAdsDto, AdResponseDto
- âœ… **Repository** - OperaÃ§Ãµes no banco (Supabase)
- âœ… **Service** - LÃ³gica de negÃ³cio
- âœ… **Controller** - Endpoints REST

### 3. MÃ³dulo de Scraper
- âœ… **FacebookApiService** - Chamadas Ã  Facebook Ads Library API
- âœ… **FacebookRateLimiterService** - Controle de rate limiting (200 req/hora)
- âœ… **AdQualityFilterService** - Filtros e algoritmo de qualidade
- âœ… **ScraperService** - OrquestraÃ§Ã£o do scraping
- âœ… **ScraperSchedulerService** - Cron jobs automÃ¡ticos
- âœ… **ScraperController** - Endpoints admin

### 4. Sistema de Qualidade
Algoritmo de pontuaÃ§Ã£o que classifica anÃºncios em:
- ðŸ¥‡ **Gold** (80+ pontos) - Melhores anÃºncios
- ðŸ¥ˆ **Silver** (60-79 pontos) - AnÃºncios bons
- ðŸ¥‰ **Bronze** (< 60 pontos) - AnÃºncios bÃ¡sicos

**CritÃ©rios de pontuaÃ§Ã£o:**
- Dias rodando (atÃ© 30 pontos)
- Qualidade do texto (15 pontos)
- TÃ­tulo e descriÃ§Ã£o (20 pontos)
- Tipo de mÃ­dia (20 pontos)
- MÃºltiplas plataformas (10 pontos)
- Gasto estimado (15 pontos)
- ImpressÃµes (10 pontos)

### 5. Rate Limiting & SeguranÃ§a
- âœ… Limite de 200 requisiÃ§Ãµes por hora
- âœ… Delay de 3 segundos entre requisiÃ§Ãµes
- âœ… Retry automÃ¡tico em caso de erro
- âœ… Exponential backoff
- âœ… Monitoramento de headers do Facebook

### 6. Cron Jobs AutomÃ¡ticos
- âœ… Scraping a cada 6 horas (todos os paÃ­ses exceto BR)
- âœ… Scraping diÃ¡rio Ã s 2h (paÃ­ses principais)

---

## ðŸ“¦ INSTALAÃ‡ÃƒO

### 1. Instalar dependÃªncias
```bash
cd backend
npm install
```

### 2. Criar arquivo .env
Copie o `.env.example` e preencha com suas credenciais:

```bash
cp .env.example .env
```

**VariÃ¡veis obrigatÃ³rias:**
```env
# Supabase (pegar em: https://supabase.com/dashboard)
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_KEY=sua-chave-aqui

# Facebook (pegar em: https://developers.facebook.com)
FACEBOOK_ACCESS_TOKEN=seu-token-aqui
FACEBOOK_APP_ID=seu-app-id
FACEBOOK_APP_SECRET=seu-secret

# ConfiguraÃ§Ãµes
PORT=3000
NODE_ENV=development
MIN_DAYS_RUNNING=4
GOLD_SCORE_THRESHOLD=80
SILVER_SCORE_THRESHOLD=60
FACEBOOK_REQUESTS_PER_HOUR=200
SCRAPER_DELAY_MS=3000
```

### 3. Executar banco de dados
Execute o script SQL no seu Supabase:
```sql
-- Executar o arquivo banco-de-dados.sql no Supabase SQL Editor
```

### 4. Rodar aplicaÃ§Ã£o
```bash
# Desenvolvimento (com watch)
npm run start:dev

# ProduÃ§Ã£o
npm run build
npm run start:prod
```

---

## ðŸ”‘ COMO OBTER CREDENCIAIS

### Supabase
1. Acesse: https://supabase.com/dashboard
2. Crie um projeto (ou use existente)
3. VÃ¡ em **Settings â†’ API**
4. Copie:
   - `URL` â†’ `SUPABASE_URL`
   - `anon public` â†’ `SUPABASE_KEY`

### Facebook Ads Library
1. Acesse: https://developers.facebook.com
2. Crie um app tipo "Business"
3. Adicione produto "Marketing API"
4. VÃ¡ em **Tools â†’ Graph API Explorer**
5. Selecione seu app e gere token com permissÃµes:
   - `ads_read`
   - `pages_read_engagement`
6. **IMPORTANTE:** Token de usuÃ¡rio expira! Use token de longa duraÃ§Ã£o:
   ```
   https://graph.facebook.com/v21.0/oauth/access_token?
   grant_type=fb_exchange_token&
   client_id=SEU_APP_ID&
   client_secret=SEU_APP_SECRET&
   fb_exchange_token=SEU_TOKEN_CURTO
   ```

---

## ðŸ“¡ ENDPOINTS DA API

### AnÃºncios (PÃºblicos)

#### Listar anÃºncios com filtros
```http
GET /ads?country_code=US&quality_tier=gold&limit=20&page=1
```

**Query params:**
- `search` - Busca por texto
- `country_code` - Filtrar por paÃ­s
- `category_id` - Filtrar por categoria
- `quality_tier` - gold, silver ou bronze
- `media_type` - image, video ou carousel
- `is_featured` - true/false
- `min_days_running` - Dias mÃ­nimos rodando
- `sort_by` - views, favorites, performance, days_running
- `sort_order` - asc ou desc
- `limit` - Resultados por pÃ¡gina (1-100)
- `page` - NÃºmero da pÃ¡gina

#### Buscar por ID
```http
GET /ads/:id
```

#### AnÃºncios Gold (melhores)
```http
GET /ads/gold?limit=50
```

#### AnÃºncios em Trending
```http
GET /ads/trending?limit=50
```

#### MÃ©tricas gerais
```http
GET /ads/metrics
```

#### Registrar visualizaÃ§Ã£o
```http
POST /ads/:id/view
Body: { "userId": "uuid" }
```

### Scraper (Admin)

#### Executar scraping manual
```http
POST /scraper/run
Body: {
  "searchTerms": "fitness",
  "countries": ["US", "GB", "CA"]
}
```

#### Scraping por paÃ­ses
```http
POST /scraper/run-by-country
Body: {
  "countries": ["US", "ES", "MX"]
}
```

#### Status do scraper
```http
GET /scraper/status
```

**Response:**
```json
{
  "success": true,
  "rateLimit": {
    "requestCount": 45,
    "maxRequests": 200,
    "resetTime": "2024-01-15T14:00:00.000Z",
    "remainingRequests": 155
  }
}
```

---

## ðŸ§ª TESTANDO A APLICAÃ‡ÃƒO

### 1. Testar conexÃµes
Ao iniciar, vocÃª verÃ¡:
```
ðŸš€ Iniciando aplicaÃ§Ã£o Gringads...

ðŸ“Š Testando conexÃ£o Supabase...
âœ… Supabase conectado com sucesso!
âœ… ConexÃ£o Supabase testada com sucesso!
âœ… Supabase OK!

ðŸ“± Testando config Facebook...
âœ… Facebook config carregado!
   â†’ Limite: 200 req/hora
   â†’ Delay: 3000ms entre requests
âœ… Facebook OK!
   URL API: https://graph.facebook.com/v21.0
   Rate Limit: 200 req/hora
   Delay: 3s
```

### 2. Testar API bÃ¡sica
```bash
curl http://localhost:3000
```

Resposta:
```json
"ðŸŽ‰ API Gringads funcionando! Backend para anÃºncios escalados do Facebook Ads."
```

### 3. Executar scraping de teste
```bash
curl -X POST http://localhost:3000/scraper/run \
  -H "Content-Type: application/json" \
  -d '{
    "countries": ["US"],
    "searchTerms": ""
  }'
```

### 4. Listar anÃºncios
```bash
curl http://localhost:3000/ads?limit=10
```

---

## ðŸ”„ CRON JOBS AUTOMÃTICOS

### Scraping a cada 6 horas
Busca anÃºncios de todos os paÃ­ses (exceto BR) automaticamente.

### Scraping diÃ¡rio Ã s 2h
Busca anÃºncios dos paÃ­ses principais:
- US, GB, CA, AU, DE, FR, ES, MX, IT, NL

**Para desabilitar:** Remova ou comente os decorators `@Cron()` em:
```typescript
// backend/src/scraper/services/scraper-scheduler.service.ts
```

---

## ðŸ“Š MONITORAMENTO

### Rate Limit Status
```bash
curl http://localhost:3000/scraper/status
```

### Logs importantes
- âœ… ConexÃµes estabelecidas
- ðŸ” Scraping iniciado
- ðŸ“Š AnÃºncios encontrados/salvos
- â³ Rate limit atingido
- âš ï¸ Avisos de rate limit prÃ³ximo do limite
- âŒ Erros

---

## ðŸ›¡ï¸ SEGURANÃ‡A & BOAS PRÃTICAS

### Rate Limiting
- **200 requisiÃ§Ãµes/hora** por access token
- **Delay de 3 segundos** entre requests
- Monitoramento de headers `X-App-Usage`
- Pausa automÃ¡tica ao atingir limite

### PrevenÃ§Ã£o de Ban
- âœ… Retry com exponential backoff
- âœ… Tratamento de erros 429 (rate limit)
- âœ… Tratamento de erros 500/503 (servidor)
- âœ… Logs detalhados
- âœ… NÃ£o fazer requests paralelos

### Duplicatas
- VerificaÃ§Ã£o por `facebook_ad_id` (unique)
- Uso de `upsert` para atualizar existentes
- NÃ£o inserir anÃºncios repetidos

---

## ðŸ› TROUBLESHOOTING

### Erro: "Cannot find module"
```bash
cd backend
npm install
```

### Erro: "SUPABASE_URL deve estar definido"
Verifique se:
- O arquivo `.env` existe
- NÃ£o hÃ¡ espaÃ§os: `SUPABASE_URL=valor` âœ… (nÃ£o `SUPABASE_URL = valor` âŒ)
- O arquivo estÃ¡ na raiz do `/backend`

### Erro: "Rate limit exceeded"
Aguarde 1 hora ou ajuste em `.env`:
```env
FACEBOOK_REQUESTS_PER_HOUR=150
SCRAPER_DELAY_MS=5000
```

### Erro ao conectar Facebook
Verifique se:
- Access token Ã© vÃ¡lido (nÃ£o expirou)
- App tem permissÃµes `ads_read`
- Token Ã© de longa duraÃ§Ã£o

### Nenhum anÃºncio encontrado
PossÃ­veis causas:
- PaÃ­ses/termos de busca muito especÃ­ficos
- Filtros muito restritivos (dias mÃ­nimos)
- HorÃ¡rio sem anÃºncios ativos

---

## ðŸ“ˆ PRÃ“XIMOS PASSOS

### AutenticaÃ§Ã£o (Fase 2)
- [ ] MÃ³dulo Auth com Supabase Auth
- [ ] Guards de proteÃ§Ã£o de rotas
- [ ] Sistema de roles (admin/user)

### Assinaturas Hotmart (Fase 2)
- [ ] Webhook Hotmart
- [ ] ValidaÃ§Ã£o de assinatura ativa
- [ ] RLS no Supabase

### Frontend (Fase 3)
- [ ] Next.js com TailwindCSS
- [ ] Dashboard com filtros
- [ ] PÃ¡gina de detalhes do anÃºncio
- [ ] Sistema de favoritos

---

## ðŸ“š ARQUITETURA

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ supabase.config.ts       # ConexÃ£o Supabase
â”‚   â”‚   â””â”€â”€ facebook.config.ts       # Config Facebook
â”‚   â”‚
â”‚   â”œâ”€â”€ ads/                          # MÃ³dulo de AnÃºncios
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â””â”€â”€ ad.entity.ts         # Tipos
â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚   â”œâ”€â”€ create-ad.dto.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ filter-ads.dto.ts
â”‚   â”‚   â”‚   â””â”€â”€ ad-response.dto.ts
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ ads.repository.ts    # Queries Supabase
â”‚   â”‚   â”œâ”€â”€ ads.service.ts           # LÃ³gica de negÃ³cio
â”‚   â”‚   â”œâ”€â”€ ads.controller.ts        # Endpoints
â”‚   â”‚   â””â”€â”€ ads.module.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ scraper/                      # MÃ³dulo de Scraping
â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚   â””â”€â”€ facebook-ad.dto.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ facebook-api.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ facebook-rate-limiter.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ ad-quality-filter.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.service.ts
â”‚   â”‚   â”‚   â””â”€â”€ scraper-scheduler.service.ts
â”‚   â”‚   â”œâ”€â”€ scraper.controller.ts
â”‚   â”‚   â””â”€â”€ scraper.module.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ app.module.ts                 # MÃ³dulo raiz
â”‚   â”œâ”€â”€ app.service.ts
â”‚   â””â”€â”€ main.ts                       # Entry point
â”‚
â”œâ”€â”€ .env                              # VariÃ¡veis (nÃ£o commitar!)
â”œâ”€â”€ .env.example                      # Exemplo
â””â”€â”€ package.json
```

---

## ðŸŽ¯ CONCLUSÃƒO

VocÃª agora tem um backend completo e robusto para:
- âœ… Buscar anÃºncios escalados do Facebook Ads Library
- âœ… Filtrar apenas os melhores (Gold/Silver/Bronze)
- âœ… Salvar no Supabase com todas as mÃ©tricas
- âœ… API REST completa com filtros e paginaÃ§Ã£o
- âœ… Rate limiting para evitar ban
- âœ… Scraping automÃ¡tico com cron jobs

**Pronto para produÃ§Ã£o!** ðŸš€

Agora Ã© sÃ³:
1. Configurar `.env` com suas credenciais
2. Executar `npm run start:dev`
3. Fazer primeiro scraping: `POST /scraper/run`
4. Consultar anÃºncios: `GET /ads`

**DÃºvidas?** Consulte a documentaÃ§Ã£o ou verifique os logs da aplicaÃ§Ã£o.

